
---
title: "Confirmation Bias"
description: "A personal reflection on building my own standards, choosing my own path, and living beyond external expectations."
pubDatetime: 2026-01-11T00:00:00Z
tags: ["mental model"]
featured: false

---

## [Confirmation Bias And the Power of Disconfirming Evidence](https://fs.blog/confirmation-bias/)

>Our use of this cognitive shortcut is understandable. Evaluating evidence (especially when it is complicated or unclear) requires a great deal of mental energy. Our brains prefer to take shortcuts. This saves the time needed to make decisions, especially when we’re under pressure. As many evolutionary scientists have pointed out, our minds are unequipped to handle the modern world. For most of human history, people experienced very little new information during their lifetimes. Decisions tended to be survival based. Now, we are constantly receiving new information and have to make numerous complex choices each day. To stave off overwhelm, we have a natural tendency to take shortcuts.

>Confirmation bias is somewhat linked to our memories (similar to availability bias). We have a penchant for recalling evidence that backs up our beliefs. However neutral the original information was, we fall prey to selective recall.

Can I interpret here as positive way: What you believe actually can give you lots of power.
For example, if I believe as long as I am alive, I always have the opportunity to do the things I want, in some day I can definitely make them happen.

### Why We Ignore Contradicting Evidence
>Much of this is the result of our need for cognitive consistency. We are bombarded by information. It comes from other people, the media, our experience, and various other sources. Our minds must find means of encoding, storing, and retrieving the data we are exposed to. One way we do this is by developing cognitive shortcuts and models. These can be either useful or unhelpful.

That's why we like use tags to categorize people, we simplify, and we don't care about the truth.
This is the cognitive model behind:

- Racism / sexism (e.g. "women aren’t good at math")
    
- Echo chambers ("those people are stupid")
    
- Organizational silos ("marketing people don’t get it")



>we are motivated to think critically only when held accountable by others. If we are expected to justify our beliefs, feelings, and behaviors to others, we are less likely to be biased towards confirmatory evidence. This is less out of a desire to be accurate, and more the result of wanting to avoid negative consequences or derision for being illogical. Ignoring evidence can be beneficial, such as when we side with the beliefs of others to avoid social alienation.

>Suppose an individual believes something with his whole heart; suppose further that he has a commitment to this belief, that he has taken irrevocable actions because of it; finally, suppose that he is presented with evidence, unequivocal and undeniable evidence, that his belief is wrong: what will happen? The individual will frequently emerge, not only unshaken but even more convinced of the truth of his beliefs than ever before. Indeed, he may even show a new fervor about convincing and converting people to his view.

Agreed, people will even more be convinced about their beliefs. 

---

## [Falsification: How to Destroy Incorrect Ideas](https://fs.blog/peter-cathcart-wason-falsification/)

The only way to test the validity of any theory was to prove it wrong, a process he labeled falsification. And it turns out we’re quite bad at falsification.

>Subjects were told that they would be given a series of three numbers that followed a certain rule known only to the experimenter. Their assignment was to figure out what the rule was, which they could do by offering the experimenter other strings of three numbers and asking him whether or not these new strings met the rule.
>
>The string of numbers the subjects were given was quite simple:
>
>2-4-6
>
>Try it: What’s your first instinct about the rule governing these numbers? And what’s another string you might test with the experimenter in order to find out if your guess is right? If you’re like most people, your first instinct is that the rule is “ascending even numbers” or “numbers increasing by two.” And so you guess something like:
>
>8-10-12
>
>And the experimenter says, “Yes! That string of numbers also meets the rule.” And your confidence rises. To confirm your brilliance, you test one more possibility, just as due diligence, something like:
>
>20-22-24
>
>“Yes!” says the experimenter. Another surge of dopamine. And you proudly make your guess: “The rule is: even numbers, ascending in twos.” “No!” says the experimenter. It turns out that the rule is “any ascending numbers.” So 8-10-12 does fit the rule, it’s true, but so does 1-2-3. Or 4-23-512. The only way to win the game is to guess strings of numbers that would prove your beloved hypothesis wrong—and that is something each of us is constitutionally driven to avoid.

We can’t always test by looking for evidence that supports our current idea; instead, we should ask ourselves, **“What evidence would show me I’m wrong?”**

### Investing Example

**Belief:** “This company has a strong competitive advantage.”

- **Confirmation:** You look for news articles praising the company, or you read bullish reports.
    
- **Falsification:** You ask, “What would make me question this advantage?”
    
    - _Example tests:_
        
        - Are competitors gaining market share?
            
        - Is the company’s profit margin shrinking compared to peers?
            
        - Have key executives left?
            
        - Are customers switching to alternatives?
            
    - If you find convincing evidence here, it might show your original thesis is wrong.


## [Why do we favor our existing beliefs?](https://thedecisionlab.com/biases/confirmation-bias)

>Confirmation bias is particularly present in the consumption of news and media. The ever-evolving ease of access has allowed the population to personally curate what they consume.

It’s like being trapped in an information cocoon—we keep seeing only what supports our beliefs. That’s why it’s so important to stay open-minded and actively seek out views that challenge us.

#### How it affects product
>This is confirmation bias at work: if we dislike a celebrity who endorses a product, we are more likely to attend to information that suggests that we will also dislike the product.
>
>Consumers will often consult reviews before buying a product – this gives them a good idea of whether or not that item will be useful and valuable. Upon researching, if they are primed with an abundance of positive reviews, they may be likely to seek to confirm information when using it themselves

So true

##### How to avoid it

>Confirmation bias is likely to occur when we are gathering the information needed to make decisions. It is also subconscious; we are unaware of its influence on our decision-making. As such, the first step to avoiding confirmation bias is making ourselves aware of it. Because confirmation bias is most likely to occur early in the decision-making process, we should focus on starting with a neutral fact base. This can be achieved by having multiple objective sources of information.